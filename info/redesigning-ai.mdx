---
title: Redesigning AI
date: '2024-03-18'
tags: ['AI']
draft: false
summary: A look at how new technologies can be put to use in the creation of a more just society.Artificial Intelligence (AI) is not likely to make humans redundant.
images: []
---

## MetaSummary

1. Organizations are increasingly investing in data and algorithmic sophistication to support decision-making, yet the returns on these investments appear limited in many contexts due to uncertainty and the effectiveness of simple heuristics over complex algorithms.

2. The study evaluates the returns of algorithms in an Inspections Department, demonstrating that algorithms, both simple and sophisticated, outperform human rankings in predicting health code violations in restaurants, with substantial gains in identifying violations.

3. Despite the predictive gains from algorithms, inspectors often override algorithmic recommendations based on their discretion, leading to decisions that do not necessarily improve outcomes, indicating a potential misalignment between algorithmic predictions and inspectors' decision-making processes.

4. Interviews with 55 departments revealed a consistent provision of decision authority to inspectors, suggesting a widespread recognition of the value of human judgment in decision-making processes, despite the availability of algorithmic tools.

5. The study suggests that integrating data into the decision process through simple heuristics yields the greatest gains in decision quality, highlighting the importance of the context in which algorithms are used and how decision authority is allocated.

6. The findings underscore the crucial role of decision authority in the effectiveness of algorithms in decision-making, suggesting that the design and management of decision authority significantly impact the value organizations can capture from using predictive analytics.

7. The research indicates that the gains from using algorithms come from integrating any data into the decision process, rather than increasing algorithmic sophistication or adding more data, challenging the notion that more complex algorithms necessarily provide better predictions.

8. The study's analysis reveals that inspectors were less likely to inspect algorithm-recommended restaurants, diminishing the benefits of using algorithms, and tended to prioritize restaurants based on their own rankings, potentially reducing the effectiveness of algorithms in decision-making.

9. The paper concludes that managing decision authority is crucial when using algorithms as decision aids, as the returns to algorithmic sophistication may be limited in some contexts, and organizations should evaluate the returns to algorithmic sophistication in each context.

10. The study contributes to the understanding of how the use of algorithms as decision aids translates into improvements in managerial decisions, emphasizing the need for more research on how decision-makers leverage their contextual knowledge and discretion when faced with algorithmic inputs.

## Sub Summaries

### Promoting Inclusive Prosperity and Democratic Freedoms in AI Development.

1. AI technologies are rapidly advancing and have the potential to revolutionize various sectors, but they also pose threats such as unemployment, disinformation, bias, and surveillance.
2. The future impact of AI on work and democracy is not predetermined, and there is a possibility to create inclusive prosperity and bolster democratic freedoms through thoughtful government policy, industry norms redirection, and democratic oversight.
3. Current AI research is narrowly focused and may lead to social upheaval due to excessive work automation and lack of investment in human productivity, which can displace workers and undermine democracy.
4. Shared prosperity and democratic political participation are essential for modern society, and the weakening of democracy can make it more challenging to address the adverse effects of AI on labor markets and distribution.
5. The COVID\-19 crisis has accelerated the drive for automation, posing additional challenges to job displacement and distributional effects of AI.
6. The direction of AI development can be altered to increase human productivity, create jobs, shared prosperity, and protect democratic freedoms through modifications in AI funding, regulation, researcher norms, and societal oversight.
7. Historical examples, such as the post\-World War II era, demonstrate that technological progress, combined with labor market institutions and new job opportunities, can lead to shared economic growth and social cohesion.
8. Labor market institutions, such as minimum wages, collective bargaining, and worker protections, play a crucial role in generating broad\-based wage growth and creating "good jobs" when combined with technological advancements that increase worker productivity.

### Impact of AI on Labor Market and Democracy in U.S.

1. Technologies boosting human productivity and labor market institutions protecting workers were mutually self\-reinforcing, leading to good jobs and shared prosperity in postwar economies.

2. In the decades following World War II, U.S. businesses operated in a competitive environment, leading to investments in technology that raised worker productivity and created advantages for firms.

3. Government support, funding, and involvement in research efforts played a crucial role in the development of iconic technologies, contributing to rapid productivity growth and shared prosperity.

4. The shift towards more automation and less focus on increasing worker productivity since the 1980s has led to slower wage growth, inequality, and job losses in certain industries.

5. Changes in policy, institutional environments, and government funding have favored automation over labor, contributing to the widening wage gaps between different income groups.

6. The evolution of AI has shifted towards algorithmic automation, replacing repetitive and simple cognitive tasks performed by low\-wage workers, with forecasts suggesting a significant impact on various occupations in the future.

7. Factors such as increased polarization, breakdown of traditional media models, and the influence of money in politics have negatively impacted U.S. democracy, making effective policy\-making and bipartisan efforts more challenging.

8. AI\-powered social media platforms have transformed political communication and debate, leading to concerns about disinformation, polarization, lack of trust in institutions, and political rancor.

### AIs impact on democracy, privacy, and societal values in technology.

1. The use of AI in political advertising and social media algorithms contributes to the polarization of the public in the U.S. and poses a threat to democracy and liberty worldwide.
2. AI technologies, such as facial recognition, have the potential to enable governments to control dissent and discourage opposition, leading to a reduction in civic participation and individual freedoms.
3. The focus of AI research on automation and surveillance technologies limits the potential for AI to complement human capabilities in various sectors, such as education, healthcare, and entertainment, by creating new tasks and increasing productivity.
4. Emerging technologies, such as differential privacy and secure multiparty computation, have the potential to protect privacy and democracy, but their implementation in commercial products and services is still limited.
5. Relying solely on the market to drive technological innovation may not lead to the most socially beneficial outcomes, as market forces may not account for externalities and societal values.
6. The market's focus on economic incentives may overlook noneconomic costs and benefits, such as erosion of liberties and job security, leading to suboptimal technological development.
7. Norms and social objectives play a crucial role in shaping technological innovation, and leaving the market to itself may not align with society's best interests.
8. Redistributive measures alone are insufficient to address the challenges posed by technological advancements, and a balance between job creation, social purpose, and democracy is essential for shared prosperity.

### Promoting Socially Beneficial AI Research Through Government, Norms, and Oversight

1. A progressive tax system and social safety net have historically supported shared prosperity, but jobs, especially good jobs, have been the main engine of prosperity, driven by productivity growth and labor market institutions.
2. Nordic countries exemplify how productivity growth, job creation, and shared gains in the labor market have been central to their social democratic compact, with industry\-level wage agreements fostering high and equal wages, productivity growth, and job creation.
3. The control of AI research is concentrated in the hands of a few tech giants, influencing the direction of research through funding, academic relations, and philanthropic efforts.
4. Government policy, funding, and leadership are critical in redirecting AI research towards socially beneficial areas, similar to successful efforts in redirecting technological change in energy generation.
5. A three\-pronged approach involving government involvement, norms shifting, and democratic oversight is proposed to redirect AI research towards beneficial applications and away from excessive automation and surveillance technologies.
6. Government policy should focus on removing distortions that encourage automation, supporting research efforts towards socially beneficial technologies, and measuring the impact of AI applications on the labor share to prioritize technologies that increase labor share.
7. Norms shifting involves raising awareness among AI researchers and society about the social consequences of AI applications, triggering self\-reinforcing changes in norms.
8. Democratic oversight is essential for transparent decision\-making and accountability in AI research, breaking the cycle of decisions made by a small group of companies and researchers.
9. Despite challenges such as weakening democracy and accelerated automation trends due to the pandemic, a transformation towards better AI is possible through rejuvenating democracy, societal norms, and democratic oversight.

### International coordination for redirecting AI towards productive, ethical development.

1. The international dimension of AI technology poses a challenge as researchers in other countries can continue pursuing surveillance and military applications, making it necessary for the United States to consider international coordination for redirecting AI.

2. The future of AI, economy, and democracy are in our hands, but we must not underestimate the challenges we face.

3. Technological progress, specifically AI, poses economic and political challenges, with automation exacerbating inequality in the labor market.

4. AI not only impacts economic inequality but also poses threats to democracy, liberty, and social justice.

5. Redirecting AI development towards a more productive path requires interventions beyond redistribution, as technological unemployment presents a real challenge.

6. The assumption that work and meaning are necessarily linked needs to be questioned, as exploring a wider array of policy possibilities is necessary to address the threat of automation.

7. Workers' rights must be a nonnegotiable priority in any program of redirection, as technology is being used for control, punishment, and profit extraction, particularly affecting marginalized communities.

8. Corporations use technology to extract maximum value and profit from workers, leading to job loss, deskilling, and increased surveillance, highlighting the importance of strong labor protections and organizations.

### Promoting Worker Rights and Empowerment in the Workplace

1. Walmart and Amazon have implemented punitive labor practices through the use of centralized scheduling algorithms, robots, and surveillance technology to maximize profits at the expense of worker well\-being.

2. These practices have led to high levels of stress, anxiety, and injuries among workers, as well as hindering their ability to organize and speak out against poor working conditions.

3. The COVID\-19 pandemic has exacerbated existing inequalities in the workforce, particularly impacting marginalized workers, women, and workers of color.

4. To address these challenges, there is a need for policies that establish robust worker rights, ensure stable schedules, and prioritize worker empowerment in the workplace.

5. Job creation, labor policy reform, and worker empowerment are identified as key priorities to address the interrelated issues of job quality, job quantity, and inequality in the workforce.

6. Strengthening labor market institutions, raising the minimum wage, and implementing new forms of worker voice and power are essential steps towards creating a more equitable future of work.

7. Government intervention, such as through economic stimulus plans and infrastructure projects, is crucial to creating job opportunities and supporting workers during times of economic uncertainty.

8. Without structural changes to incentivize good jobs, defund policing and militarization, and ensure corporations pay their fair share, the current trends of exploitative labor practices will continue to prevail.

### Empowering workers in the age of AI and automation.

1. Workers express lack of control over technologies deployed by employers, leading to feelings of being a cost to minimize and profit to maximize.
2. Union membership at historically low levels limits workers' formal avenues for having a voice in the workplace.
3. Challenges faced by workers seeking a seat at the table as work is transformed, illustrated by Amazon's actions against a union effort.
4. Public support for structural reforms post\-pandemic may help redirect AI towards shared prosperity.
5. Advanced AI technologies are fundamentally limited and cannot replace most human tasks.
6. Acemoglu's argument overstates technology's responsibility for job crisis, leading to unlikely solutions for shared prosperity.
7. Slowdown in growth rates globally is not due to automation\-driven reduction in jobs, but rather a lack of opportunities for workers to transition to better jobs.
8. Need for a new economic engine not reliant on growth for social stability, with a focus on public investment for broad social benefits.
9. Benefits of AI technologies are not equally shared, with harms disproportionately affecting vulnerable and marginalized groups.
10. Decolonial AI is necessary to address algorithmic harm rooted in colonial legacies, including algorithmic oppression, exploitation, and dispossession.

### Addressing algorithmic coloniality challenges in AI development for equity.

1. Unrepresentative datasets in AI development lead to biased resource allocation and exacerbate health inequalities for underserved populations during the COVID\-19 pandemic.
2. Algorithmic coloniality encompasses oppression, exploitation, and dispossession, with exploitation being evident in the outsourcing of data annotation to jurisdictions with limited labor laws, erasing workers' rights and protections.
3. Dispossession in AI centralizes power and assets, limiting certain forms of expression and communication, shaping regulatory policy, and benefiting the Global North at the expense of other regions.
4. Steps can be taken to achieve a more just future for AI by realigning modern technology to interconnect stakeholders and prioritize shared prosperity.
5. Prosperity in AI should encompass economic productivity, dignity, rights expansion, open society, and vibrant social and political community.
6. Decolonial AI efforts involve developing a critical technical practice by considering social implications, advancing participatory methods, and merging participatory action research with machine learning.
7. Industry must reform AI development and deployment to empower communities, rebalance risks and benefits, and ensure social and economic gains benefit all stakeholders.
8. Systemic change beyond the AI industry is necessary, including establishing greater public awareness and scrutiny of AI applications, higher standards for data collection and annotation, and deeper research on sociotechnical factors.
9. AI ethics principles must be deepened and aligned with human and civil rights law to address algorithmic coloniality challenges and ensure AI serves the interests of all stakeholders.

### Promoting Human-AI Collaboration for Enhanced Performance and Societal Benefits.

1. A/B tests by Cresta show benefits for customers and newer workers, closing wage gap and reducing inequality.
2. Managers and business leaders need to rethink work processes to create novel value with technology and people working together.
3. Taxation policies can influence decision\-making and shared prosperity, suggesting a need to level the playing field.
4. AI should be seen as a supplement to human work, not a replacement, to enhance collaboration and performance.
5. Automation\-only approaches have limitations in adaptability, scalability, and interpretability, urging a shift towards human\-AI collaboration.
6. Collaborative systems in manufacturing and education can improve outcomes by leveraging human and AI capabilities.
7. Changing the narrative from human\-AI competition to collaboration poses design challenges but offers higher value and societal benefits.

### AI-driven automation: Impact on workplace power dynamics and democratic safeguards.

1. AI\-driven automation is leading to a weakening of democratic safeguards, as it shifts power dynamics in the workplace towards employers.
2. The current automation debate swings between dystopian and utopian visions, but overlooks the negative impacts on workers in low\-wage jobs.
3. The encroachment of AI into the workplace mirrors historical practices of industrial labor exploitation, with employers using AI to observe, assess, and modulate work cycles.
4. Workers in AI\-modulated workplaces experience increased surveillance, algorithmic assessment, and strict modulation of time, leading to a loss of agency and autonomy.
5. The transformation of the workplace by AI includes uncertain work hours, increased surveillance through "bossware," and the rise of the gig economy, creating new forms of precarity for workers.
6. Policy responses to AI must go beyond redistribution and address the shifting of risk from employers to workers, as well as privacy\-abusing practices of bossware.
7. Government policy should aim to steer the development of AI away from automation that has negative consequences for individuals and societies, by removing policy distortions, changing research norms, and rejuvenating democratic governance.

### Promoting Ethical AI Development and Academic Research Prioritization.

1. The brain drain of AI talent from academia to industry is a worrisome trend, leading to research that may prioritize corporate interests over societal flourishing.
2. The access to computing power and data in big tech companies is a significant factor driving talent towards industry.
3. Policy interventions, such as increasing federal AI science budgets and creating a national research cloud, can address the issue of brain drain and support academic research.
4. Universities offer settings for interdisciplinary research and collaboration that can shape the development of AI for the better, emphasizing academic freedom over corporate control.
5. The impact of AI on labor markets and democracy can be redirected through policy choices and social norms.
6. Algorithmic fairness definitions may perpetuate social inequalities and profit\-maximizing objectives, highlighting the need for an inequality\- and power\-based framework.
7. External regulation, advocacy, and oversight are necessary to ensure ethical considerations in AI development, as corporations prioritize profit maximization.
8. A wider range of agents of change, including marginalized groups, should be involved in shaping the future of AI to address algorithmic harms and promote a more just society.

### Empowering workers and reshaping AI for ethical, just development.

1. Current AI development is focused on automation and monitoring, with a few large companies influencing the direction of technology.
2. Some believe that job loss to automation is inevitable, leading to the need for decoupling work and income through schemes like universal basic income.
3. Digital technologies and AI have contributed to worker disempowerment, especially affecting minorities and women in the service sector.
4. Efforts to empower workers and redirect technological change must go hand\-in\-hand to address the negative impacts of AI.
5. Regulation of the technology sector, diverse voices, and more power for workers are necessary but may not be sufficient to address the challenges posed by AI.
6. Social norms must change to ensure effective regulation and accountability in the use of AI technologies.
7. The economic system needs a fundamental transformation to address the challenges posed by AI, focusing on public investment and democratically designed protocols.
8. Redirecting technological change in AI requires a shift away from profit\-driven automation and monitoring towards creating jobs, opportunities, and supporting individual freedom and democracy.
9. Ethical reflection, questioning the goals and consequences of AI technologies, and considering the purpose of AI tools are essential for a just future in AI development.

### Ethical considerations in AI development and deployment in society.

1. The decision to deploy, optimize, or not build AI tools depends on empirical factors such as how the tool works, the problem it solves, and its interaction with social structures.
2. Non\-deployment of AI tools that have already been built is a viable option, as seen in recent bans of law enforcement facial recognition tools in U.S. cities.
3. The unregulated use of facial recognition systems can be politically and morally objectionable, even if they could be made highly accurate for everyone.
4. The pursuit of social justice may be undermined by tools that support ordinary policing practices in a systemically unjust society.
5. Nuanced, context\-specific frameworks are needed for ethical and political reflection on AI development and deployment.
6. The cultural imperative to prioritize speed in technology development may hinder ethical considerations and lead to suboptimal outcomes.
7. Industry AI ethics efforts may be limited by competing corporate goals, as seen in Google's firing of Ethical AI team leads.
8. The argument that developing potentially harmful technology is better than leaving it to bad actors is flawed, as even well\-intentioned tools can have damaging effects.
9. AI tools can be unjust even without biased training data, as they may reflect and exacerbate social biases and inequalities.
10. The potential harms of AI extend beyond datasets and error rates, including the use of technology for morally illegitimate goals and conveying harmful messages.
11. The presumption that non\-deployment is always an option may not hold true, especially without industry\-wide regulation, as seen in irreversible labor effects of automation.
12. The pressure to automate may lead companies to simulate AI tools, making it difficult to revert to pre\-automated structures once tools are built and deployed.

### Ensuring Ethical AI Development and Training for Economic Security.

1. Non\-deployment of AI technology does not eliminate ethical and political risks associated with its use.
2. Decision\-making regarding the development and deployment of AI systems should involve considerations of justice and societal impacts.
3. Rather than focusing solely on optimizing existing practices with AI, it is important to question what a more just system would look like and what transformations are needed.
4. Systematic regulation and democratic oversight are necessary for AI development, along with new governance frameworks at national and international levels.
5. AI should not be viewed in isolation but rather in the context of historical technological development and parallels with other powerful technologies.
6. The skill crisis in the U.S. is not due to inadequate education but rather a lack of investment by businesses in workforce training and career development.
7. Smaller businesses, which make up the majority of employer firms, often lack resources for workforce training, leading to economic disparity.
8. Workplace training is essential for low\-income workers trapped in low\-wage jobs that could be automated in the future.
9. Higher education alone may not guarantee economic security, and improving the quality of entry\-level jobs is crucial.
10. Raising the minimum wage can benefit low\-wage workers but may also lead to automation and job loss in some cases.
11. Employers may respond to higher wages by upskilling workers or replacing them with technology, highlighting the need for additional support beyond wage legislation.
12. Workplace training and institutional support are essential components for improving job opportunities and economic security for low\-wage workers.

### Enhancing job security and skill development for frontline workers.

1. Proposal for job\-site mentoring to pair frontline workers with technical experts for idea sharing and peer advocacy, leading to increased job security and support.

2. Recommendation for employer\-sponsored training and off\-site coursework to enhance skill development, potentially through tuition reimbursement or apprenticeship programs, to enable career advancement and higher earnings for workers like Maddie.

3. Argument for employers to take greater responsibility for skill development to improve job quality and economic opportunity for workers on the lowest rungs of the labor market.

4. Emphasis on the shared value of skill for both workers and employers, highlighting the importance of skill development for productivity, innovation, and economic resilience.

5. Exploration of the ambiguity and malleability of the concept of skill, suggesting that embracing this ambiguity can lead to institutional action to enhance the work experience of economically vulnerable workers.

6. Introduction of workforce intermediaries as a model for enhancing employment prospects through organizational expansion, by formalizing structures for work\-based learning and linking firms with educational institutions for skill development opportunities.

7. Description of workforce intermediaries' role in reducing employer training costs, strengthening employer\-educational institution partnerships, and creating a shared social responsibility for skill development.

8. Recognition of the challenges faced by workforce intermediaries in influencing employer decision\-making, transforming "bad jobs into good," and addressing the impact of technological change on skill sets.

### Empowering frontline workers in shaping technological progress and innovation.

1. The traditional approach to technological change involves institutions stepping in after firms have chosen new technologies, but there is a more proactive and embedded approach that involves engaging frontline workers in the innovation process from the start.
2. Examples such as the Culinary Workers Union in Las Vegas and building trades unions in northern California demonstrate the benefits of involving frontline workers in technological decision\-making and development.
3. By involving frontline workers in technological decisions, employers can realize the value of their input and advocate for wider adoption of innovative solutions.
4. This alternative vision challenges the idea that technological change is predetermined and inevitable, emphasizing the importance of workforce institutions in shaping technological progress.
5. The intersection of inclusion and innovation offers an opportunity for new forms of labor advocacy that treat skill development and innovation as interconnected.
6. Advocates must reconcile older labor traditions with more recent movements to build worker mobilization and political power, pushing back against the assumption that technological changes are inherently disruptive to jobs.
7. Empowering workforce institutions to elevate their influence over technology development and choice is essential, moving beyond simply matching skills to the latest technological trends.
8. Strategies of skill reinterpretation must support the work of the future by promoting workers' skills as crucial to technological progress and establishing skill development as a protected worker right.

9. Medical data in the field of medicine, including machine learning applications, can be incomplete, incorrect, missing, and biased.
10. Machine learning systems can centralize power at the expense of patients and healthcare providers, exacerbating imbalances of power.
11. Machine learning designers and adopters must consider how new systems interface with a medical system that can be disempowering and traumatic for patients.
12. Domain expertise, including that of patients, must not be disregarded in the development and adoption of machine learning systems.
13. The conversation around bias and fairness in medical data must focus on power and participation, recognizing the impact on those whose lives are changed by algorithmic outcomes.
14. Flaws in medical data, such as biases in tools like pulse oximeters and Fitbit heart rate monitors, can lead to misleading clinical outcomes and disparities in care.
15. Diagnosis delays and disbelief of patient symptoms can result in incomplete and missing data, impacting the accuracy of machine learning models.
16. It is imperative to consider tests that aren't ordered, notes that aren't recorded, and listen to patients about the completeness and accuracy of their data in working with medical datasets.

### Empowering patients in machine learning for fair medical practices.

1. Machine learning centralizes power away from those most affected by the technology, amplifying biases and creating pernicious feedback loops across systems.
2. Examples of harmful impacts of machine learning include governments using facial recognition, corporations using surveillance, and misappropriation of datasets by agencies like U.S. Immigration and Customs Enforcement.
3. Implementation of machine learning in medicine can lead to errors, lack of recourse, and negative impacts on patients, as seen in cases like health care cuts for people with cerebral palsy due to algorithm errors.
4. Patients' experiences in the medical system, including dismissals and misdiagnoses, highlight the need to consider how machine learning interfaces with an already flawed and distressing system.
5. Medical expertise is not limited to doctors; patients possess essential skills and expertise, and their input is crucial in ensuring accurate diagnoses and treatment.
6. Machine learning in medicine must move beyond explainability to provide recourse and contestability, empowering patients and challenging power dynamics.
7. Efforts to address bias and fairness in machine learning, such as the Participatory Approaches to Machine Learning workshop, aim to shift power dynamics and prioritize user participation.
8. The future of AI poses challenges in labor markets, with AI\-driven automation potentially displacing human workers and centralizing power in the hands of technology owners.
9. Skepticism about the impact of AI is warranted, as the potential for AI to surpass human cognitive abilities may lead to significant disruptions in the labor market.

### AIs Evolution and Limitations: Engineering vs Cognitive Science Debate

1. The initial optimism surrounding the development of fully general artificial intelligence in the 1960s has not been fully realized even after over half a century.
2. AI has evolved significantly since its early days and has become a major focus of academic research and a lucrative industry.
3. The dominance of deep learning approaches in AI landscape has overshadowed logic\-based symbolic processing approaches, leading to skepticism about the overselling of AI's promise and potential.
4. The distinction between AI\-as\-engineering and AI\-as\-cognitive science is crucial, with the former focusing on practical applications and the latter on understanding and reverse engineering the human mind.
5. Deep learning, while successful in extracting patterns from large datasets, may not hold the key to unlocking human\-like intelligence due to its reliance on statistical analysis rather than cognitive structures.
6. The debate over the role of deep learning in understanding human cognition highlights the importance of distinguishing between AI\-as\-engineering and AI\-as\-cognitive science.
7. The limitations of current AI approaches suggest that the development of thinking robots or a singularity merging human and machine intelligence is unlikely in the near future.
8. Despite the uncertainties surrounding AI's impact on human cognition, the engineering of powerful cognitive networks involving human and artificial intelligence remains a significant development.

### Cognitive labor division in AI engineering for future networks.

1. The division of cognitive labor between human and artificial intelligence within engineered cognitive networks is a significant and ongoing issue.
2. AI\-as\-engineering has the potential to reduce the role of human cognitive labor within future cognitive networks.
3. Much of the cognitive work currently done by humans within cognitive networks does not require the full range of human cognitive capacities.
4. The emergence of the Internet of things will lead to a highly data\-driven economy, requiring significant cognitive labor to manage.
5. AI\-as\-engineering may lead to a decrease in the demand for human cognitive labor within the overall economy.
6. Decisions about the development and deployment of AI should involve all relevant stakeholders and be intentional and deliberative.
7. Technology, including AI, is developed and deployed by humans and must be guided by collective will to enhance rather than diminish the human world.
8. Utopian cheerleading for AI may overlook potential negative impacts on human work and society.
9. AI has the potential to transform the boundary between work for machines and work for humans, leading to a reevaluation of human purpose and roles in society.

### Shift of cognitive labor from humans to AI in networks.

1. The increasing integration of AI into cognitive networks, such as air traffic control systems, medical diagnostic systems, and ground transportation systems, has led to a shift in the balance of cognitive labor from humans to machines.
2. The use of AI in these systems has significantly improved safety and efficiency, with AI systems often outperforming humans in tasks such as decision\-making and problem\-solving.
3. The trend of offloading cognitive labor onto intelligent machines is likely to continue and accelerate with advancements in AI technology.
4. The potential future implications of this trend include a reduction in the need for human labor in certain industries, such as transportation, as intelligent machines take on more responsibilities.
5. While some roles within cognitive networks may still require human input, the nature of these roles is likely to evolve, leading to a transformation in the way humans interact with AI systems.
6. The increasing reliance on AI in cognitive networks raises questions about the future role of humans in decision\-making processes and the potential impact on job markets and economic structures.
7. The author suggests that the integration of AI into various cognitive networks may lead to a future where human beings are marginalized or eliminated from certain roles, with intelligent machines taking on more responsibilities.

### Addressing biases in robotics and implications for automating care work.

1. The rise of automation and robotics raises urgent questions about the future of work, economy, and human cognitive labor.
2. The introduction of medical robots like Grace in healthcare settings presents both opportunities and challenges in providing care.
3. The increasing interest and investment in robotics raise concerns about the impact on human workers, especially in the field of care work.
4. While robots may provide support and minimize exposure to unsafe conditions for human workers in the short term, the long\-term implications of automation must be considered.
5. The discussion of care robots must acknowledge the existing inequalities in the care work sector, particularly affecting poor women of color.
6. Automation does not guarantee a more just labor market and may exacerbate existing social and economic vulnerabilities if labor justice is not prioritized.
7. Algorithms in robotics tend to replicate biases and inequalities present in society, leading to issues like racial bias in AI systems.
8. The design and programming of robots like Grace, Erica, and EngKey reflect gendered and racial biases, impacting the delivery of care and interactions with diverse populations.
9. Concerns about race in robotics extend to how robots interpret and interact with diverse faces, highlighting the potential harm of automating care work through coded biases.
10. The concept of "coded care" provides a framework for understanding the harmful implications of automating care work and the need to address biases in AI systems.

### Promoting equitable and just automation in care services.

1. Concerns about coded care and the debate over whether robotic automation is the best solution for addressing labor shortages.
2. The potential consequences of outsourcing care to robots, including the impact of racist and gendered biases in the code on those receiving care.
3. The importance of labor justice as a precondition for the adoption of automation, especially considering the disproportionate impact on women and communities of color.
4. The negative effects of mistreating care workers, as seen in examples like EngKey's robot teachers, on both the workers and those receiving care.
5. The need for more equitable and accountable artificial intelligence, working with organizations like the Algorithmic Justice League to address biases in coding.
6. The proposal for socially responsible automation, which involves investing in training and building the skills of human workers to adapt to technology\-driven workplaces.
7. The call for a framework of labor justice in developing care robots, supported by initiatives like the Essential Workers Bill of Rights.
8. The importance of addressing racialized and gendered perceptions in the design of care robots to ensure algorithms truly care.
9. The necessity of centering principles of justice and equity in coding care, rather than solely focusing on simulating humanity.
10. The argument for a society where both human workers and robots coexist, with a focus on developing algorithms that truly care.

## Metadata

**File Path:** `/Users/andrew/Dropbox/04_research/AI_econ_jobs_future/Kim_Glaeser_2023_Decision_authority_returns_to_algorithms.pdf`

**Config:** subsumm model: gpt-4-turbo-preview. Metasummary model: gpt-4-turbo-preview

## BibTeX Record

```
@book{acemoglu2021redesigning,
  title={Redesigning Ai},
  author={Acemoglu, Daron},
  year={2021},
  publisher={MIT Press}
}
```
